{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " First generate ds1_stats running python script generate_stats_for_ds_1.py \n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import sys\n",
    "#param\n",
    "\n",
    "if len(sys.argv)<3:\n",
    "    print(\"Enter valid query folder as argument\")\n",
    "    sys.exit()\n",
    "elif len(sys.argv)>3:\n",
    "    print(\"Invalid Arguments\")\n",
    "    sys.exit()\n",
    "elif sys.argv[2] != '-ds1' or sys.argv[2] != '-ds2':\n",
    "    print('Enter valid flag -ds1 , -ds2 ')\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# query_folder = \"query_data/\"\n",
    "query_folder = sys.argv[1]\n",
    "# metric_flag = '-ds1'\n",
    "metric_flag = sys.argv[2]\n",
    "\n",
    "\n",
    "if metric_flag == '-ds1':\n",
    "    if not os.path.isfile('Results/ds1_stats.csv') :\n",
    "        print(' First generate ds1_stats running python script generate_stats_for_ds_1.py ')\n",
    "        sys.exit()\n",
    "if metric_flag == '-ds2':\n",
    "    if not os.path.isfile('Results/ds2_stats.csv') :\n",
    "        print(' First generate ds2_stats running python script generate_stats_for_ds_2.py ')\n",
    "        sys.exit()\n",
    "onlyfiles = [f for f in listdir(query_folder) if isfile(join(query_folder, f)) and \"_bme\" in f]\n",
    "# print(onlyfiles)\n",
    "dates = []\n",
    "for f in onlyfiles:\n",
    "    date = f.split(\"_\")[0]\n",
    "    dates.append(date)\n",
    "# print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "plt.style.use(\"seaborn-talk\")\n",
    "\n",
    "import seaborn as sns\n",
    "from dateutil import tz\n",
    "import pytz \n",
    "import tqdm\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.stats import entropy\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "import folium\n",
    "from branca.element import Figure\n",
    "from folium.plugins import HeatMapWithTime, HeatMap\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# reading and preprocessing related functions\n",
    "def read_raw(folder,date):\n",
    "    \"\"\"\n",
    "    Reads in the data. Does not remove any row. \n",
    "    \"\"\"\n",
    "#     if len(str(date[8:])) == 2:\n",
    "    df_bme = pd.read_csv(folder + \"/\" + date + \"_bme.csv\", index_col= 0)\n",
    "    df_gps = pd.read_csv(folder + \"/\" + date + \"_gps.csv\", index_col = 0)\n",
    "    df_pol = pd.read_csv(folder + \"/\" + date + \"_pol.csv\", index_col = 0)\n",
    "#     else:\n",
    "#         df_bme = pd.read_csv(\"data/\" + date + \"_bme.csv\", index_col= 0)\n",
    "#         df_gps = pd.read_csv(\"data/\" + date + \"_gps.csv\", index_col = 0)\n",
    "#         df_pol = pd.read_csv(\"data/\" + date + \"_pol.csv\", index_col = 0)\n",
    "    return df_bme, df_gps, df_pol\n",
    "\n",
    "def handle_dateTime(df_all):\n",
    "    ## change dateTime column from type \"object\" to \"datetime\"\n",
    "    df_all[\"dateTime\"] = pd.to_datetime(df_all.dateTime)    \n",
    "    # convert to India timing\n",
    "    to_zone = tz.gettz('Asia/Kolkata')\n",
    "    df_all.dateTime = df_all.dateTime.apply(lambda x: pytz.utc.localize(x, is_dst=None).astimezone(to_zone))\n",
    "    return df_all\n",
    "\n",
    "def make_time_cols(df_all):\n",
    "    df_all[\"hour\"] = df_all.dateTime.dt.hour\n",
    "    df_all[\"minute\"] = df_all.dateTime.dt.minute    \n",
    "    return df_all\n",
    "\n",
    "def preprocess(df_tuple):\n",
    "    \"\"\"\n",
    "    Combines all other functions\n",
    "    \"\"\"\n",
    "    df_bme, df_gps, df_pol = df_tuple\n",
    "    \n",
    "    # drop duplicates\n",
    "    df_bme = df_bme.drop_duplicates(subset =\"uid\" )\n",
    "    df_gps = df_gps.drop_duplicates(subset = \"uid\")\n",
    "    df_pol = df_pol.drop_duplicates(subset = \"uid\")\n",
    "    \n",
    "    # merge on key columns\n",
    "    key_cols = [\"uid\", \"dateTime\", \"deviceId\"]\n",
    "    df_all = pd.merge(df_bme, df_gps, on = key_cols)\n",
    "    df_all = pd.merge(df_all, df_pol , on = key_cols)\n",
    "    \n",
    "    # rename lng to long and shorten device IDs\n",
    "    df_all = df_all.rename(columns = {\"lng\":\"long\"})\n",
    "    df_all.deviceId = df_all.deviceId.str[-5:]\n",
    "    \n",
    "    # handle dateTime and time related columns\n",
    "    df_all = handle_dateTime(df_all)\n",
    "    df_all = make_time_cols(df_all)\n",
    "    \n",
    "    # some final stuff \n",
    "    df_all = df_all.sort_values(\"dateTime\")\n",
    "    df_all = df_all.reset_index(drop = True)\n",
    "    return df_all\n",
    "\n",
    "\n",
    "def plot_plotwise_for_all_dates():\n",
    "    result = []\n",
    "    counter = 1\n",
    "    print('Generating ds_1 stats for dates',dates)\n",
    "    print('Progress ',0,'of',len(dates))\n",
    "    for dt in dates :\n",
    "        df_bme, df_gps, df_pol = read_raw(query_folder,dt)\n",
    "        df_all = preprocess((df_bme, df_gps, df_pol))\n",
    "        sensor_order = df_all.deviceId.unique()\n",
    "        sensor_order.sort()\n",
    "        \n",
    "        sub = df_all.groupby([\"deviceId\", \"hour\", \"minute\"]).size().reset_index()\n",
    "#         fig, ax = plt.subplots(1, 1, figsize = (15, 5))\n",
    "#             print(sub.describe())\n",
    "#         print(sub.groupby([\"deviceId\"])[0].describe())\n",
    "        result.append(sub.groupby([\"deviceId\"])[0].describe())\n",
    "#         g = sns.boxplot(y = 0, data = sub, x= \"deviceId\", order = sensor_order)\n",
    "#         g.set_ylabel(\"Samples Recorded per Minute\")\n",
    "#         g.set_title(dt+ \": Boxplots for Sampling Rate (Samples Recorded per Minute)\")\n",
    "\n",
    "#         plt.show()\n",
    "        \n",
    "        print('Progress ',counter,'of',len(dates))\n",
    "        counter +=1\n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = plot_plotwise_for_all_dates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File Results/ds1_stats.csv does not exist: 'Results/ds1_stats.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-20ef65a4d4bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mds1_stats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Results/ds1_stats.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'metric'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds1_stats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Finding anomaly based ob below stats : '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds1_stats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-----------------------------------------------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chinmay\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chinmay\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chinmay\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chinmay\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chinmay\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File Results/ds1_stats.csv does not exist: 'Results/ds1_stats.csv'"
     ]
    }
   ],
   "source": [
    "ds1_stats = pd.read_csv('Results/ds1_stats.csv',index_col='metric')\n",
    "stats = ds1_stats.to_dict()\n",
    "print('Finding anomaly based ob below stats : ')\n",
    "print(ds1_stats)\n",
    "print('-----------------------------------------------------')\n",
    "# ds1_stats['lower_limit']['median']\n",
    "lower_median = stats['lower_limit']['25th_percentile']\n",
    "upper_median = stats['upper_limit']['75th_percentile']\n",
    "lower_25th = stats['lower_limit']['25th_percentile']\n",
    "upper_25th = stats['upper_limit']['75th_percentile']\n",
    "lower_75th = stats['lower_limit']['25th_percentile']\n",
    "upper_75th = stats['upper_limit']['75th_percentile']\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = \"query_data/\"\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f)) and \"_bme\" in f]\n",
    "# print(onlyfiles)\n",
    "dates = []\n",
    "for f in onlyfiles:\n",
    "    date = f.split(\"_\")[0]\n",
    "    dates.append(date)\n",
    "# print(dates)\n",
    "\n",
    "\n",
    "# merge with upper cell\n",
    "anamolus_flag = False\n",
    "# print(len(query_result))\n",
    "for idx,date in enumerate(query_result):\n",
    "    for device in range(len(date)):\n",
    "        anomalous_score = 0\n",
    "        device_median = date.iloc[device]['50%']\n",
    "        device_25th = date.iloc[device]['25%']\n",
    "        device_75th = date.iloc[device]['75%']\n",
    "        if lower_median> device_median or device_median > upper_median:\n",
    "            anomalous_score +=1\n",
    "        if lower_25th> device_25th or device_25th > upper_25th:\n",
    "            anomalous_score +=1\n",
    "        if lower_75th> device_75th or device_75th > upper_75th:\n",
    "            anomalous_score +=1\n",
    "        \n",
    "        # anamolus detection logic\n",
    "        if anomalous_score >= 2 : \n",
    "            deviceName = query_result[0].index.values[device]\n",
    "            print('deviceID : ',deviceName,'is behaving anamolusly on date:',dates[idx])\n",
    "            anamolus_flag = True\n",
    "#             result = print_stats_for_date(dt)\n",
    "            print('Below are stats for date',dates[idx])\n",
    "            print(query_result[idx])\n",
    "        \n",
    "if not anamolus_flag:\n",
    "    print('No anamolus device for metric ds_1 on dates',dates)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(query_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(query_result[0].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_result[0].index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
