{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Arguments\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chinmay\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import sys\n",
    "#param\n",
    "\n",
    "if len(sys.argv)<2:\n",
    "    print(\"Enter valid data folder as argument\")\n",
    "    sys.exit()\n",
    "elif len(sys.argv)>2:\n",
    "    print(\"Invalid Arguments\")\n",
    "    sys.exit()\n",
    "    \n",
    "\n",
    "# data_folder = \"test_data/\"\n",
    "data_folder = sys.argv[1]\n",
    "\n",
    "\n",
    "onlyfiles = [f for f in listdir(data_folder) if isfile(join(data_folder, f)) and \"_bme\" in f]\n",
    "# print(onlyfiles)\n",
    "dates = []\n",
    "for f in onlyfiles:\n",
    "    date = f.split(\"_\")[0]\n",
    "    dates.append(date)\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "plt.style.use(\"seaborn-talk\")\n",
    "\n",
    "import seaborn as sns\n",
    "from dateutil import tz\n",
    "import pytz \n",
    "import tqdm\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.stats import entropy\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "import folium\n",
    "from branca.element import Figure\n",
    "from folium.plugins import HeatMapWithTime, HeatMap\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# reading and preprocessing related functions\n",
    "def read_raw(folder,date):\n",
    "    \"\"\"\n",
    "    Reads in the data. Does not remove any row. \n",
    "    \"\"\"\n",
    "#     if len(str(date[8:])) == 2:\n",
    "    df_bme = pd.read_csv(folder + \"/\" + date + \"_bme.csv\", index_col= 0)\n",
    "    df_gps = pd.read_csv(folder + \"/\" + date + \"_gps.csv\", index_col = 0)\n",
    "    df_pol = pd.read_csv(folder + \"/\" + date + \"_pol.csv\", index_col = 0)\n",
    "#     else:\n",
    "#         df_bme = pd.read_csv(\"data/\" + date + \"_bme.csv\", index_col= 0)\n",
    "#         df_gps = pd.read_csv(\"data/\" + date + \"_gps.csv\", index_col = 0)\n",
    "#         df_pol = pd.read_csv(\"data/\" + date + \"_pol.csv\", index_col = 0)\n",
    "    return df_bme, df_gps, df_pol\n",
    "\n",
    "def handle_dateTime(df_all):\n",
    "    ## change dateTime column from type \"object\" to \"datetime\"\n",
    "    df_all[\"dateTime\"] = pd.to_datetime(df_all.dateTime)    \n",
    "    # convert to India timing\n",
    "    to_zone = tz.gettz('Asia/Kolkata')\n",
    "    df_all.dateTime = df_all.dateTime.apply(lambda x: pytz.utc.localize(x, is_dst=None).astimezone(to_zone))\n",
    "    return df_all\n",
    "\n",
    "def make_time_cols(df_all):\n",
    "    df_all[\"hour\"] = df_all.dateTime.dt.hour\n",
    "    df_all[\"minute\"] = df_all.dateTime.dt.minute    \n",
    "    return df_all\n",
    "\n",
    "def preprocess(df_tuple):\n",
    "    \"\"\"\n",
    "    Combines all other functions\n",
    "    \"\"\"\n",
    "    df_bme, df_gps, df_pol = df_tuple\n",
    "    \n",
    "    # drop duplicates\n",
    "    df_bme = df_bme.drop_duplicates(subset =\"uid\" )\n",
    "    df_gps = df_gps.drop_duplicates(subset = \"uid\")\n",
    "    df_pol = df_pol.drop_duplicates(subset = \"uid\")\n",
    "    \n",
    "    # merge on key columns\n",
    "    key_cols = [\"uid\", \"dateTime\", \"deviceId\"]\n",
    "    df_all = pd.merge(df_bme, df_gps, on = key_cols)\n",
    "    df_all = pd.merge(df_all, df_pol , on = key_cols)\n",
    "    \n",
    "    # rename lng to long and shorten device IDs\n",
    "    df_all = df_all.rename(columns = {\"lng\":\"long\"})\n",
    "    df_all.deviceId = df_all.deviceId.str[-5:]\n",
    "    \n",
    "    # handle dateTime and time related columns\n",
    "    df_all = handle_dateTime(df_all)\n",
    "    df_all = make_time_cols(df_all)\n",
    "    \n",
    "    # some final stuff \n",
    "    df_all = df_all.sort_values(\"dateTime\")\n",
    "    df_all = df_all.reset_index(drop = True)\n",
    "    return df_all\n",
    "\n",
    "\n",
    "def plot_plotwise_for_all_dates():\n",
    "    result = []\n",
    "    counter = 1\n",
    "    print('Generating ds_1 stats for dates',dates)\n",
    "    print('Progress ',0,'of',len(dates))\n",
    "    for dt in dates :\n",
    "        df_bme, df_gps, df_pol = read_raw(data_folder,dt)\n",
    "        df_all = preprocess((df_bme, df_gps, df_pol))\n",
    "        sensor_order = df_all.deviceId.unique()\n",
    "        sensor_order.sort()\n",
    "        \n",
    "        sub = df_all.groupby([\"deviceId\", \"hour\", \"minute\"]).size().reset_index()\n",
    "#         fig, ax = plt.subplots(1, 1, figsize = (15, 5))\n",
    "#             print(sub.describe())\n",
    "#         print(sub.groupby([\"deviceId\"])[0].describe())\n",
    "        result.append(sub.groupby([\"deviceId\"])[0].describe())\n",
    "#         g = sns.boxplot(y = 0, data = sub, x= \"deviceId\", order = sensor_order)\n",
    "#         g.set_ylabel(\"Samples Recorded per Minute\")\n",
    "#         g.set_title(dt+ \": Boxplots for Sampling Rate (Samples Recorded per Minute)\")\n",
    "\n",
    "#         plt.show()\n",
    "        \n",
    "        print('Progress ',counter,'of',len(dates))\n",
    "        counter +=1\n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating ds_1 stats for dates ['2020-12-23']\n",
      "Progress  0 of 1\n",
      "Progress  1 of 1\n"
     ]
    }
   ],
   "source": [
    "result = plot_plotwise_for_all_dates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats written to Results/ds1_stats.csv \n"
     ]
    }
   ],
   "source": [
    "# print(result[0])\n",
    "dist_medians = []\n",
    "dist_75 = []\n",
    "dist_25 = []\n",
    "for df in result:\n",
    "#     print(df.size())\n",
    "    for i in range(len(df)):\n",
    "#         print(df.iloc[i]['50%'])\n",
    "        dist_medians.append(df.iloc[i]['50%'])\n",
    "        dist_75.append(df.iloc[i]['75%'])\n",
    "        dist_25.append(df.iloc[i]['25%'])\n",
    "#     print('dome')\n",
    "\n",
    "# print(dist_medians)\n",
    "stats =  {'medians': dist_medians, \n",
    "        '25th': dist_25, '75th' : dist_75}  \n",
    "stats = pd.DataFrame.from_dict(stats) \n",
    "# print(stats.describe())\n",
    "stats = stats.describe()\n",
    "# print(stats_df['medians']['count'])\n",
    "lower_median = stats['medians']['25%']\n",
    "upper_median = stats['medians']['75%']\n",
    "lower_25th = stats['25th']['25%']\n",
    "upper_25th = stats['25th']['75%']\n",
    "lower_75th = stats['75th']['25%']\n",
    "upper_75th = stats['75th']['75%']\n",
    "# print(lower_median)\n",
    "metric = ['median','25th_percentile','75th_percentile']\n",
    "lower = [lower_median,lower_25th,lower_75th]\n",
    "upper = [upper_median,upper_25th,upper_75th]\n",
    "result_dict = {'metric': metric, 'lower_limit': lower, 'upper_limit': upper} \n",
    "result_df = pd.DataFrame(result_dict)\n",
    "# print(result_dict)\n",
    "result_df.to_csv('Results/ds1_stats.csv',index = False)\n",
    "\n",
    "print('stats written to Results/ds1_stats.csv ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
